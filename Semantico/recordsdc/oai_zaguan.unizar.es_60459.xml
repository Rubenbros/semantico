<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:creator>Subías Pérez, Mario</dc:creator>
  <dc:creator>Orrite Uruñuela, Carlos</dc:creator>
  <dc:title>Sistema de geolocalización basado en imágenes para dispositivos móviles</dc:title>
  <dc:identifier>http://zaguan.unizar.es/record/60459</dc:identifier>
  <dc:publisher>Universidad de Zaragoza</dc:publisher>
  <dc:date>2016</dc:date>
  <dc:description>En este proyecto fin de máster, se muestra una aplicación de realidad aumentada capaz de geolocalizar a un usuario en un entorno conocido. El sistema ha sido entrenado para funcionar en una localización real, la plaza San Felipe de Zaragoza. Al tomar una foto de la plaza, en función de los edificios que contenga la imagen, el sistema es capaz de determinar la posición desde la cual se ha tomado. Una vez realizada esta ubicación tridimensional, se superpone en la fotografía tomada una imagen 3D de la ‘Torre Nueva’, una antigua torre mudéjar que se encontraba en esa misma plaza hasta 1892 que fue derruida. Esta aplicación funciona de forma externa, enviando la imagen tomada por el terminal a un servidor remoto que realiza los cálculos. Todo este proceso resulta costoso en tiempo, lo que provoca que la aplicación no se pueda ejecutar en tiempo real. Tanto el tiempo de envío al servidor como la extracción de características de las imágenes en el proyecto previo requieren de un tiempo superior al deseado en una aplicación de tiempo real.  En este proyecto, se pretende implementar todas las operaciones del cálculo de la localización en el mismo terminal en el que se realiza la fotografía. Además, se muestra un estudio de técnicas de extracción de características para mejorar este tiempo de cómputo. Estas características serán los keypoints o puntos relevantes de la imagen. Estos keypoints se extraen mediante algoritmos de visión por computador llamados descriptores. En el proyecto previo se utiliza el descriptor SIFT que, como ya se ha mencionado, resulta costoso computacionalmente. En este proyecto el descriptor SIFT es sustituido por el descriptor BRISK, mucho más veloz, aunque menos preciso en su cometido.  Una vez se han obtenido los puntos relevantes de dos imágenes distintas, realiza un emparejamiento entre ellos con un algoritmo de matching. Es de esta forma en la cual el sistema se localiza en el entorno 3D. Los algoritmos de matching emparejan los keypoints más probables de ambas imágenes. Sin embargo, este proceso suele presentar falsos emparejamientos o espurios que deben ser eliminados. En este proyecto se presentan nuevas técnicas de realizar este filtrado para asegurar que los emparejamientos producidos sean robustos y coherentes entre sí.  En una base de datos de imágenes de la plaza San Felipe, se pueden emparejar las imágenes entre sí siguiendo el proceso anterior para obtener un modelado 3D del entorno. Con este modelado del mundo 3D, el sistema es capaz de emparejar una fotografía nueva y localizar la posición de la cámara para superponer la ‘Torre Nueva’ en la posición correcta.</dc:description>
  <dc:format>pdf</dc:format>
  <dc:language>spa</dc:language>
  <dc:type>info:eu-repo/semantics/masterThesis</dc:type>
  <dc:rights>by-nc-sa</dc:rights>
  <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
</oai_dc:dc>
<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:creator>Gil Begué, Santiago</dc:creator>
  <dc:creator>Tardós Solano, Juan Domingo</dc:creator>
  <dc:title>Sistemas de localización y construcción de mapas de alta precisión para realidad virtual y aumentada</dc:title>
  <dc:identifier>http://zaguan.unizar.es/record/64162</dc:identifier>
  <dc:publisher>Universidad de Zaragoza</dc:publisher>
  <dc:date>2017</dc:date>
  <dc:description>La técnica de localización y mapeado simultáneos, conocida por sus siglas en inglés SLAM, permite la localización libre de deriva de un robot en un entorno desconocido mediante el procesamiento de la información de sensores de a bordo, y sin la utilización de una infraestructura externa como puede ser un sistema de posicionamiento global (GPS). ORB-SLAM es el nombre del sistema de localización y construcción de mapas desarrollado por el grupo de Robótica, Percepción y Tiempo Real de la Universidad de Zaragoza que es capaz de calcular los movimientos de una cámara con unos 3 a 5 centímetros de error. Este sistema funciona con sensores de visión a bordo. En sus dos versiones de desarrollo, ORB-SLAM soporta tres tipos de cámara diferentes: cámaras monoculares, estereoscópicas y RGB-D. Durante la presente investigación, se ha añadido el soporte a cámaras con objetivo gran angular, las cuales permiten la visualización de una mayor porción de la escena. Los puntos ORB con los que trabaja este sistema se extraen con un detector de esquinas tipo FAST. Tal hecho supone que el sistema no proporciona un rendimiento deseable en entornos con ausencia de esquinas, como puede ser el pasillo de un edificio. Para solucionar esta imprecisión del sistema, durante el presente trabajo se ha desarrollado una nueva feature denominada edgelet que representa a los puntos de contorno de una escena, más comúnmente presentes en todo tipo de escenarios. Se ha demostrado además que la extracción de los edgelets de una imagen es un proceso rápido en comparación con la extracción de otros puntos de interés de renombre. Se ha ideado un descriptor que permite un excelente proceso de emparejamiento y seguimiento de estas features. Si bien, estas innovaciones requieren un trabajo futuro de profundización para adaptarlas perfectamente en el contexto de SLAM. Se ha instalado y calibrado un sistema de captura de movimiento OptiTrack en el laboratorio 1.07 del edificio Ada Byron de la Universidad de Zaragoza, con el que se ha capturado una secuencia de vídeo, conociendo en todo momento con una precisión sub-milimétrica la pose de la cámara. Se ha desarrollado una demo de realidad aumentada, comparando la experiencia de usuario si se mantiene la localización de la cámara obtenida con un sistema de captura de movimiento, o si se calcula con el sistema ORB-SLAM. Este último consigue una mejor experiencia de usuario y sensación de realismo.</dc:description>
  <dc:format>pdf</dc:format>
  <dc:language>spa</dc:language>
  <dc:type>info:eu-repo/semantics/bachelorThesis</dc:type>
  <dc:rights>by-nc-sa</dc:rights>
  <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
</oai_dc:dc>
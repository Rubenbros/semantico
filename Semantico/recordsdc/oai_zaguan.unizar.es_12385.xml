<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:creator>Cambra Linés, Ana Belén</dc:creator>
  <dc:creator>Murillo Arnal, Ana Cristina</dc:creator>
  <dc:title>Reconocimiento robusto de texto en imágenes de dispositivos móviles</dc:title>
  <dc:identifier>http://zaguan.unizar.es/record/12385</dc:identifier>
  <dc:subject>visión artificial</dc:subject>
  <dc:subject>reconocimiento</dc:subject>
  <dc:subject>ocr</dc:subject>
  <dc:subject>dispositivos móviles</dc:subject>
  <dc:publisher>Universidad de Zaragoza</dc:publisher>
  <dc:date>2013</dc:date>
  <dc:description>El procesamiento automático de imágenes tiene gran interés en el desarrollo de nuevas tecnologías y aplicaciones basadas en información visual. Hasta hace poco, estas tareas han estado limitadas a realizarse en ordenadores con gran capacidad de cómputo, debido a los altos requerimientos de los algoritmos utilizados. Sin embargo, estas limitaciones van desapareciendo gracias a las últimas generaciones de teléfonos móviles, los smartphones, que poseen capacidades de procesamiento mucho más altas. En particular, dentro del campo de la visión artificial y en particular en temas de reconocimiento automático, una tarea que se ve muy beneficiada de la portabilidad a dispositivos móviles es la detección y reconocimiento de texto, ya que se han generado nuevos ámbitos de aplicación. Con este trabajo de fin de máster se propone mejorar un sistema base existente de reconocimiento de texto en imágenes. El sistema base consiste en una aplicación para móviles capaz de extraer el texto de carteles rectangulares presentes en una fotografía capturada con el móvil. Actualmente existen muchos reconocedores de caracteres, llamados OCRs (del inglés Optical Character Recognition), que permiten extraer el texto de una imagen pero sus buenos resultados están muy condicionados a cómo se presenta el texto dentro de dicha imagen. Se requiere que el usuario enfoque con mucha precisión dónde se encuentran los textos a leer. Esta situación es una gran restricción y sobretodo muy poco realista y robusta, además de no permitir aprovechar estas tecnologías para, por ejemplo, dar servi cios a personas con problemas de visión. Aunque el prototipo tomado como base para este trabajo consigue mejorar los resultados obtenidos por un OCR convencional, sigue presentando limitaciones para el uso en escenarios generales. En particular, se va a realizar una evaluación exhaustiva del prototipo, y se va a diseñar e implementar mejoras que reduzcan las limitaciones actuales que presenta, para conseguir un reconocimiento más robusto. Dado que el campo donde se enmarca este trabajo es una rama activa dentro de la visión artificial, han aparecido nuevos enfoques dentro del reconocimiento de texto que obtienen mejores resultados que los tradicionales OCRs. Por ello, también se va a diseñar y evaluar la integración de este tipo de enfoques con el trabajo realizado. Los resultados obtenidos han sido satisfactorios, consiguiendo mejorar el prototipo base. También la evaluación realizada del proceso demuestra que éste consigue mejorar los resultados de otros OCRs existentes, además de mejorar, en determinados casos, los resultados de otras técnicas de extracción de texto más modernas. Con parte de estos resultados se redactó el siguiente articulo: “Towards robust and efficient text sign reading from a mobile phone” que fue publicado en el 2nd IEEE Workshop on Mobile Vision llevado a cabo junto con el ICCV 2011.</dc:description>
  <dc:format>pdf</dc:format>
  <dc:language>spa</dc:language>
  <dc:type>info:eu-repo/semantics/masterThesis</dc:type>
  <dc:rights>by-nc-sa</dc:rights>
  <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
</oai_dc:dc>
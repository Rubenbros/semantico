<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:creator>Pardos Cardiel, Berta</dc:creator>
  <dc:creator>Alcalá Nalvaiz, José Tomás</dc:creator>
  <dc:title>Estimación de modelos de regresión por mínimos cuadrados penalizados</dc:title>
  <dc:identifier>http://zaguan.unizar.es/record/65157</dc:identifier>
  <dc:publisher>Universidad de Zaragoza</dc:publisher>
  <dc:date>2017</dc:date>
  <dc:description>Las técnicas de regresión por mínimos cuadrados pertenecen a la estadística básica en cuanto a predicción de modelos se refiere. Sin embargo, cuando nos encontramos con un conjunto de datos de grandes dimensiones son necesarios métodos más específicos. Uno de ellos es el caso de mínimos cuadrados penalizados, que será el objetivo principal de este trabajo. La razón es que en el momento que se tiene un gran número de datos, pueden aparecer problemas de colinealidad entre variables o que el número de variables sea mayor al número de datos obtenidos, entre otros. Si se tienen variables que están muy relacionadas entre sí, es frecuente que el modelo estimado presente sobreajuste y que en este se incluyan todas las variables predictoras con coeficientes muy poco interpretables en la realidad. Por esto y otras razones que veremos, es importante aplicar técnicas de regularización.</dc:description>
  <dc:format>pdf</dc:format>
  <dc:language>spa</dc:language>
  <dc:type>info:eu-repo/semantics/bachelorThesis</dc:type>
  <dc:rights>by-nc-sa</dc:rights>
  <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
</oai_dc:dc>
<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:creator>Barriendos Sanz, Jorge</dc:creator>
  <dc:creator>Baldassarri Santa Lucía, Sandra</dc:creator>
  <dc:creator>Cerezo Bagdasari, Eva</dc:creator>
  <dc:title>Desarrollo de un agente virtual multimodal para dispositivos móviles</dc:title>
  <dc:identifier>http://zaguan.unizar.es/record/15991</dc:identifier>
  <dc:subject>agentes virtuales</dc:subject>
  <dc:subject>interacción multimodal</dc:subject>
  <dc:subject>dispositivos móviles</dc:subject>
  <dc:publisher>Universidad de Zaragoza</dc:publisher>
  <dc:date>2014</dc:date>
  <dc:description>La finalidad de este Proyecto Fin de Carrera, llevado a cabo en el seno del grupo GIGA Affective Lab, ha sido desarrollar un agente virtual para dispositivos móviles que permita una interacción multimodal y lo más natural posible con el usuario, teniendo en consideración las limitaciones de procesado intrínsecas a estos dispositivos. Para lograr dicho objetivo, las tareas que se han abordado a lo largo de la realización del proyecto son las siguientes: •	Se ha llevado a cabo la elección de las herramientas con las que implementar el agente virtual, específico para dispositivos móviles, tanto desde el punto de vista gráfico como para desarrollar cada uno de sus modos de interacción a incorporar al propio agente. Con este fin se ha realizado un exhaustivo análisis de las distintas opciones existentes así como de las utilizadas en otros proyectos de índole similar. •	Se han desarrollado los módulos necesarios para hacer posible la comunicación oral entre el agente virtual y el usuario. En este sentido, se han implementado un sintetizador de voz o TTS, que permite reproducir oralmente el discurso del agente virtual, y un reconocedor de discurso o ASR, que permite al usuario dirigirse al agente de forma oral. •	Se han desarrollado dos módulos que permiten la comunicación escrita entre el agente virtual y el usuario. En primer lugar, se ha implementado un panel deslizable, el cual reproduce textualmente los mensajes provenientes del agente virtual en el interior de la interfaz gráfica del sistema. En segunda instancia, se ha implementado un área de texto, situada dentro de la interfaz, la cual se encarga de gestionar el proceso de escritura del mensaje por parte del usuario y de enviar dicho mensaje al agente virtual.   •	Se ha dotado al sistema de una interfaz gráfica en la que el agente virtual es el elemento central de la misma, permitiendo al agente expresarse y comunicarse de forma visual con el usuario. Además, se ha desarrollado un módulo motor encargado de gestionar las animaciones, tanto corporales como faciales, que incorpora el agente virtual.   •	Se ha desarrollado también un módulo Gestor de Diálogo que permite programar al agente virtual de forma que sea capaz de mantener una conversación fluida y coherente con el usuario. Este módulo Gestor de Diálogo, basado en el Programa AB, utiliza ficheros AIML para reconocer los mensajes del usuario y llevar a cabo la búsqueda de las respuestas más adecuadas a cada uno de estos mensajes. •	Se ha dotado de aspectos emocionales a todas las modalidades de interacción entre el agente virtual y el usuario. En este sentido, se han generado distintas voces emocionales para cada uno de los estados emocionales en los que se puede encontrar el agente, se han seleccionado distintos colores de fuente y texturas para denotar diversas emociones a través del panel deslizable y se han utilizado personajes tridimensionales que incorporan animaciones que se corresponden con cada uno de los estados emocionales del agente virtual a representar. •	Se han llevado a cabo pruebas exhaustivas y sistemáticas con usuarios finales para evaluar las voces emocionales que incorpora el sistema, así como la influencia del contenido semántico de las frases y la imagen en la percepción emocional del usuario. El trabajo se ha centrado en un subconjunto de los dispositivos móviles existentes, los smartphones Android, y se ha hecho uso de la plataforma de desarrollo comercial Unity3D puesto que es la más utilizada hoy en día para desarrollar aplicaciones 3D sobre estos dispositivos.</dc:description>
  <dc:format>pdf</dc:format>
  <dc:language>spa</dc:language>
  <dc:type>info:eu-repo/semantics/masterThesis</dc:type>
  <dc:rights>by-nc-sa</dc:rights>
  <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
</oai_dc:dc>
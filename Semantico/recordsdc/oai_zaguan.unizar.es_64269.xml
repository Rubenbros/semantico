<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:creator>Burges Blanco, Ester</dc:creator>
  <dc:creator>Tolosana Calasanz, Rafael</dc:creator>
  <dc:title>Desarrollo de un sistema de workflow científico que permita la ejecución flexible de tareas en un clúster de computadores</dc:title>
  <dc:identifier>http://zaguan.unizar.es/record/64269</dc:identifier>
  <dc:publisher>Universidad de Zaragoza</dc:publisher>
  <dc:date>2017</dc:date>
  <dc:description>Los workflows científicos han surgido como una tecnología que da soporte computacional en la realización de experimentos científicos. Por una parte, un workflow puede verse como una especificación abstracta de un conjunto de tareas y sus dependencias entre sí. Estas dependencias establecen qué pasos deben realizarse para acometer un experimento científico. Por otro lado, un workflow puede verse como un programa, y un sistema de gestión de workflows como un entorno de programación especializado cuyo objetivo es la simplificación de las tareas de programación necesarias que tienen que realizar los científicos. Los sistemas de gestión de workflows científicos deben hacer una gestión eficiente de los recursos computacionales, la gestión de fallos, y así como la supervisión de los resultados intermedios y finales y la reproducibilidad total del experimento. La aproximación habitual para ejecutar un workflow en entornos de ejecución diferentes como clusters, grid o cloud consiste en la traducción de una especificación abstracta del workflow en una especificación concreta teniendo en cuenta los datos y los recursos. Sin embargo, estas aproximaciones suelen estar ligadas a soluciones concretas como la generación de un DAG (Grado dirigido acíclico) y su ejecución en un entorno High Throughput computing como HTCondor. Estas aproximaciones hacen que la monitorización, tratamientos de los fallos y gestión de recursos estén ligadas al entorno de ejecución y no a los aspectos de la especificación abstracta original. El objetivo de este proyecto es desarrollar un prototipo de sistema de workflow científico que permita definir políticas de gestión de recursos y de recuperación de fallos a nivel de aplicación. Por este motivo, se proporciona una especificación de workflows que es independiente del entorno de ejecución y que proporciona mecanismos de tolerancia a fallos para tratar fallos de aplicación (v. gr. gestión de excepciones). La especificación se realiza mediante Redes de Petri y Renew, y su diseño tendrá en cuenta que pueda ejecutarse en cualquier infraestructura: clúster Condor, contendores o incluso microservicios.</dc:description>
  <dc:format>pdf</dc:format>
  <dc:language>spa</dc:language>
  <dc:type>info:eu-repo/semantics/masterThesis</dc:type>
  <dc:rights>by-nc-sa</dc:rights>
  <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
</oai_dc:dc>
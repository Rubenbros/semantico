<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:creator>Castillón Lacasa, Rosa</dc:creator>
  <dc:creator>Concha Belenguer, Alejo</dc:creator>
  <dc:title>Evaluación de métodos densos de reconstrucción 3D a partir de imágenes</dc:title>
  <dc:identifier>http://zaguan.unizar.es/record/31943</dc:identifier>
  <dc:publisher>Universidad de Zaragoza</dc:publisher>
  <dc:date>2015</dc:date>
  <dc:description>La reconstrucción 3D es uno de los campos más relevantes de la visión por computador.En la actualidad son muchas las aplicaciones que utilizan o podrían utilizar este tipo de reconstrucciones; por ejemplo navegación de robots, topografía y realidad virtual. Existen varias técnicas de reconstrucción 3D. En este trabajo se centra la atención en la visión estéreo multivista; y en concreto en las reconstrucciones densas. A diferencia de las técnicas tradicionales no densas, cuya limitación es que sólo pueden reconstruir unos cuantos cientos de puntos salientes, en este tipo de reconstrucciones densas se estiman todos los puntos de la escena. Para ello se utiliza una secuencia de imágenes de la misma escena, tomadas desde distintos puntos de vista cercanos. Este tipo de técnicas son muy recientes y están todavía en fase de desarrollo. En este proyecto se ha utilizado la técnica DTAM (Dense Tracking and Mapping) de 2011. Este algoritmo reconstruye el mapa de la escena y estima la posición de todas las cámaras. En este caso se ha estudiado únicamente, la fase del mapeo de la escena. El objetivo es mejorar la precisión del algoritmo, y para ello se han evaluado diferentes parámetros. Se utiliza el color de los píxeles como identificador para calcular la profundidad, en este proyecto se ha aumentado el tamaño de este identificador y se han evaluado diferentes métodos para la comparación de identificadores. También se ha estudiado como afecta el regularizador en las reconstrucciones, el cual impone que píxeles cercanos tengan profundidad similar en caso de que tengan color parecido. Todos estos parámetros se han ajustado mediante experimentación. Para calcular la mejora de los resultados se han comparado las profundidades estimadas con el algoritmo con un ground truth creado a partir de datos extraídos de un sensor Kinect. Los resultados muestran que es posible mejorar la precisión en las reconstruciones mediante el ajuste de los parámetros estudiados. En concreto la mejora obtenida en este TFG es del 40 %.</dc:description>
  <dc:format>pdf</dc:format>
  <dc:language>spa</dc:language>
  <dc:type>info:eu-repo/semantics/bachelorThesis</dc:type>
  <dc:rights>by-nc-sa</dc:rights>
  <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
</oai_dc:dc>
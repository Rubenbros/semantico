<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:creator>Alonso Ruiz, Íñigo</dc:creator>
  <dc:creator>López Pellicer, Francisco Javier</dc:creator>
  <dc:title>Infraestructura de personalización y monitorización de crawlers basada en Docker</dc:title>
  <dc:identifier>http://zaguan.unizar.es/record/60823</dc:identifier>
  <dc:publisher>Universidad de Zaragoza</dc:publisher>
  <dc:date>2016</dc:date>
  <dc:description>Algunos proyectos requieren la creación de arañas web o crawlers para obtener datos concretos de la web. Estas arañas suelen ser construidas enfocadas para un uso concreto y su configuración es bastante compleja y costosa en lo que en tiempo se refiere. El objetivo de este Trabajo de Fin de Grado es el desarrollo de un sistema de creación, personalización, y monitorización de crawlers basado en contenedores virtuales Docker definidos mediante un pequeño lenguaje de configuración o DSL (Domain Specific Language) sencillo y de un sistema de persistencia de datos para la información recolectada por los crawlers. El sistema está desarrollado para poder ser utilizado para uso individual, o colectivo. Puede ser gestionado a través de línea de comandos, dando posibilidad a un uso más rápido a usuarios más expertos, o vía web, donde el sistema será gestionará la posibilidad de ser usado por varios usuarios a través de una interfaz usable y sencilla. Las funcionalidades que ofrece sobre los crawlers incluyen desde su creación, configuración, monitorización de su estado, control del mismo e incluso un buscador e indexador propio para tratar la información recogida de forma personalizada acomodándose a las necesidades de cada sistema. A pesar de que un sistema de crawling completo pueda ser muy costoso de crear, gracias a Docker y su reutilización de partes de sistemas ya construidos, la creación es casi inmediata, aparte de otras muchas ventajas que ofrece como su portabilidad y ligereza (tamaño en memoria) respecto a las máquinas virtuales convencionales. Así pues, a través de un desarrollo incremental guiado por pequeñas iteraciones, y dirigido por pruebas (inspirado en la conocida aproximación TDD - Testing Driven Development) se ha ido construyendo un sistema en constante evolución, unificando varias tecnologías para conseguir como resultado un sistema potente que posibilita la construcción casi inmediata de instancias de sistemas de crawling.</dc:description>
  <dc:format>pdf</dc:format>
  <dc:language>spa</dc:language>
  <dc:type>info:eu-repo/semantics/bachelorThesis</dc:type>
  <dc:rights>by-nc-sa</dc:rights>
  <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
</oai_dc:dc>